# **Autolysis: Automated Data Analysis and Storytelling**

This project provides an automated solution for analyzing datasets, visualizing data, and narrating insights using a Python script called `autolysis.py`. The script dynamically examines any given CSV file, generating a comprehensive analysis that includes summary statistics, visualizations, and a written narrative in Markdown format. It leverages GPT-4o-Mini (via AI Proxy) to enhance the storytelling component, making the data insights more compelling and easier to understand.

## **Features**

The script offers a variety of features to streamline data analysis. It dynamically detects column types, computes summary statistics, and identifies patterns or outliers. For numerical data, the script creates visualizations such as histograms to represent distributions effectively. Using a large language model (LLM), the tool generates a Markdown report (`README.md`) summarizing the dataset, analysis performed, and key insights. This combination of automation and AI-powered narration provides a robust solution for exploring and presenting data.

## **Getting Started**

Before using the script, ensure you have Python 3.8 or later installed, along with the required Python libraries (`pandas`, `matplotlib`, `seaborn`, `httpx`, and `chardet`). You’ll also need an AI Proxy Token to enable GPT-4o-Mini integration. Set the token as an environment variable (`AIPROXY_TOKEN`) to ensure secure access. 

To get started, clone the repository and install the dependencies listed in `requirements.txt`. After setting up your environment, you can run the script with any CSV file to generate the analysis and visualizations.

## **Usage**

To use the script, simply run it from the command line with the dataset file name as an argument. For example:
```bash
python autolysis.py goodreads.csv
```

Once executed, the script creates a `README.md` file in the current directory containing the analysis. For numerical columns in the dataset, visualizations are saved as PNG files. These outputs can be used for further exploration or reporting purposes.

## **Directory Structure**

The outputs generated by the script are structured for clarity and ease of access. For example, if you run the script on the `goodreads.csv` dataset, the results will be stored in a directory named `goodreads/`. This directory will include a Markdown file (`README.md`) detailing the analysis and PNG images for each visualization. The directory structure ensures that outputs for different datasets are neatly organized.

## **Example**

As an example, running the script on `goodreads.csv` will produce a `goodreads/` folder containing the analysis and visualizations. The `README.md` file in the folder will summarize the dataset’s structure, provide key statistics, and narrate insights. PNG files representing the distribution of numerical columns will also be saved in the folder, making it easy to share findings with others.

## **License**

This project is licensed under the MIT License, allowing for wide usage and contributions. For more details, refer to the `LICENSE` file included in the repository.

## **Contributing**

Contributions to this project are welcome. Whether you want to suggest features, report bugs, or improve the code, feel free to fork the repository, make your changes, and submit a pull request. Collaboration is encouraged to enhance the project further.

## **Contact**

If you have any questions or need support, you can reach out via email or open an issue in the GitHub repository. We look forward to hearing your feedback and ideas to improve the project.
